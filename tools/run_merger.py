#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
EDS Data Merger - Basit Ã‡alÄ±ÅŸtÄ±rÄ±cÄ±
===================================

Bu script, EDS verilerini birleÅŸtirmek iÃ§in basit bir arayÃ¼z saÄŸlar.
Sadece Ã§alÄ±ÅŸtÄ±rÄ±n ve adÄ±mlarÄ± takip edin!

Usage: python run_merger.py
"""

import os
import sys
from pathlib import Path

# Ana merger'Ä± import et
sys.path.append(str(Path(__file__).parent))
from advanced_data_merger import AdvancedDataMerger

def print_banner():
    """GÃ¼zel bir banner yazdÄ±r"""
    print("="*60)
    print("ğŸš¨ EDS VERÄ° BÄ°RLEÅTÄ°RÄ°CÄ° - Advanced Data Merger")
    print("="*60)
    print("ğŸ“Š TÃ¼m EDS verilerinizi tek bir kaliteli veri setinde birleÅŸtirin!")
    print()

def check_input_directory():
    """Input dizinini kontrol et"""
    scraped_dir = Path("../scrapers/scraped-datas")
    
    if not scraped_dir.exists():
        print("âŒ scraped-datas dizini bulunamadÄ±!")
        print(f"   Beklenen konum: {scraped_dir.absolute()}")
        return None
    
    # DosyalarÄ± listele
    files = list(scraped_dir.glob("*"))
    data_files = [f for f in files if f.suffix.lower() in ['.json', '.geojson', '.csv']]
    
    if not data_files:
        print("âŒ scraped-datas dizininde veri dosyasÄ± bulunamadÄ±!")
        print("   Desteklenen formatlar: .json, .geojson, .csv")
        return None
    
    print(f"âœ… {len(data_files)} veri dosyasÄ± bulundu:")
    for file in data_files:
        size_mb = file.stat().st_size / (1024 * 1024)
        print(f"   ğŸ“„ {file.name} ({size_mb:.1f}MB)")
    
    return str(scraped_dir)

def get_user_preferences():
    """KullanÄ±cÄ± tercihlerini al"""
    print("\nğŸ”§ AYARLAR:")
    print("-" * 20)
    
    # Kalite eÅŸiÄŸi
    while True:
        try:
            quality = input("ğŸ“Š Minimum kalite eÅŸiÄŸi (0.1-1.0) [varsayÄ±lan: 0.3]: ").strip()
            if not quality:
                quality = 0.3
                break
            quality = float(quality)
            if 0.1 <= quality <= 1.0:
                break
            else:
                print("   âš ï¸  LÃ¼tfen 0.1-1.0 arasÄ±nda bir deÄŸer girin")
        except ValueError:
            print("   âš ï¸  LÃ¼tfen geÃ§erli bir sayÄ± girin")
    
    # Dublika mesafesi
    while True:
        try:
            distance = input("ğŸ“ Dublika tespit mesafesi (km) [varsayÄ±lan: 0.1]: ").strip()
            if not distance:
                distance = 0.1
                break
            distance = float(distance)
            if 0.01 <= distance <= 5.0:
                break
            else:
                print("   âš ï¸  LÃ¼tfen 0.01-5.0 arasÄ±nda bir deÄŸer girin")
        except ValueError:
            print("   âš ï¸  LÃ¼tfen geÃ§erli bir sayÄ± girin")
    
    # Output dizini
    output_dir = input("ğŸ“‚ Ã‡Ä±ktÄ± dizini [varsayÄ±lan: merged-output]: ").strip()
    if not output_dir:
        output_dir = "merged-output"
    
    return {
        'min_quality': quality,
        'duplicate_threshold': distance,
        'output_dir': output_dir
    }

def run_merger_with_progress(input_dir, preferences):
    """Merger'Ä± progress ile Ã§alÄ±ÅŸtÄ±r"""
    print("\nğŸš€ VERÄ° BÄ°RLEÅTÄ°RME BAÅLATILIYOR...")
    print("=" * 40)
    
    try:
        # Merger oluÅŸtur
        merger = AdvancedDataMerger(input_dir, preferences['output_dir'])
        merger.duplicate_detector.distance_threshold = preferences['duplicate_threshold']
        
        print("ğŸ“¥ 1/4 - Veri dosyalarÄ± yÃ¼kleniyor...")
        raw_data = merger.load_all_data()
        
        print("ğŸ”§ 2/4 - Veriler normalize ediliyor...")
        normalized_points = merger.normalize_data(raw_data)
        
        print("ğŸ” 3/4 - Dublikalar tespit ediliyor ve birleÅŸtiriliyor...")
        duplicate_groups = merger.duplicate_detector.find_duplicates(normalized_points)
        
        if duplicate_groups:
            merged_points = merger.duplicate_detector.merge_duplicates(normalized_points, duplicate_groups)
            print(f"   âœ… {len(duplicate_groups)} dublika grubu birleÅŸtirildi")
        else:
            merged_points = normalized_points
            print("   âœ… Dublika bulunamadÄ±")
        
        # Kalite filtreleme
        high_quality_points = [
            point for point in merged_points 
            if point.confidence_score >= preferences['min_quality']
        ]
        
        print("ğŸ’¾ 4/4 - SonuÃ§lar export ediliyor...")
        merger.export_data(high_quality_points)
        
        return high_quality_points, merger.stats
        
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")
        return None, None

def show_results(points, stats, output_dir):
    """SonuÃ§larÄ± gÃ¶ster"""
    if not points:
        print("\nâŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z!")
        return
    
    print("\nğŸ‰ Ä°ÅLEM TAMAMLANDI!")
    print("=" * 40)
    print(f"ğŸ“Š Toplam kaliteli nokta: {len(points)}")
    print(f"ğŸ¯ Ortalama kalite skoru: {sum(p.confidence_score for p in points) / len(points):.3f}")
    print(f"ğŸ“‚ Ã‡Ä±ktÄ± dizini: {output_dir}")
    
    # Tip daÄŸÄ±lÄ±mÄ±
    from collections import Counter
    type_dist = Counter(p.type for p in points)
    print(f"\nğŸ“ˆ Kamera Tip DaÄŸÄ±lÄ±mÄ±:")
    for camera_type, count in type_dist.most_common():
        print(f"   {camera_type}: {count} adet")
    
    # Åehir daÄŸÄ±lÄ±mÄ± (en Ã§ok 5 ÅŸehir)
    city_dist = Counter(p.city for p in points if p.city)
    print(f"\nğŸ™ï¸  En Ã‡ok KameranÄ±n OlduÄŸu Åehirler:")
    for city, count in city_dist.most_common(5):
        print(f"   {city}: {count} adet")
    
    print(f"\nğŸ“ OluÅŸturulan dosyalar:")
    output_path = Path(output_dir)
    for file in output_path.glob("eds_merged_data_*"):
        print(f"   ğŸ“„ {file.name}")
    
    print(f"\nâœ… ArtÄ±k bu verileri EDS uyarÄ± sisteminizde kullanabilirsiniz!")

def main():
    """Ana fonksiyon"""
    print_banner()
    
    # Input dizini kontrol
    input_dir = check_input_directory()
    if not input_dir:
        print("\nğŸ’¡ Ã–NERÄ°:")
        print("   1. Ã–nce scrapers/scraped-datas dizininizde veri olduÄŸundan emin olun")
        print("   2. python egm_eds_parser.py ile veri toplayÄ±n")
        print("   3. Bu script'i tekrar Ã§alÄ±ÅŸtÄ±rÄ±n")
        return
    
    # KullanÄ±cÄ± tercihleri
    preferences = get_user_preferences()
    
    # Onay
    print(f"\nğŸ“‹ Ã–ZET:")
    print(f"   ğŸ“¥ Kaynak: {input_dir}")
    print(f"   ğŸ“Š Min. kalite: {preferences['min_quality']}")
    print(f"   ğŸ“ Dublika mesafesi: {preferences['duplicate_threshold']} km")
    print(f"   ğŸ“‚ Ã‡Ä±ktÄ±: {preferences['output_dir']}")
    
    confirm = input(f"\nâ“ Ä°ÅŸleme baÅŸlansÄ±n mÄ±? (e/h) [e]: ").strip().lower()
    if confirm and confirm not in ['e', 'evet', 'y', 'yes']:
        print("âŒ Ä°ÅŸlem iptal edildi.")
        return
    
    # Ä°ÅŸlemi Ã§alÄ±ÅŸtÄ±r
    points, stats = run_merger_with_progress(input_dir, preferences)
    
    # SonuÃ§larÄ± gÃ¶ster
    show_results(points, stats, preferences['output_dir'])

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâŒ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan iptal edildi.")
    except Exception as e:
        print(f"\nâŒ Beklenmeyen hata: {e}")
        print("ğŸ“§ Bu hatayÄ± rapor edebilirsiniz.")
